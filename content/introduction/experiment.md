---
title: Статистический эксперимент
---

# Статистический эксперимент

{{< hint warning >}}
Во вводной главе будут **ОЧЕНЬ** поверхностно обрисованы все темы, которые мы покроем за семестр. Неудивительно, что сходу во все Вы въехать не сможете, останутся вопросы. Это нормально. Мы всё разберем на мелкие детали, Вы ко всему привыкнете, но всему свое время, иначе эта лекция будет километровой.  
Мой совет:  
1. Кровь из носу надо въехать в идею параметризации.
2. Во всем, что касается статистик, задач, асимптотики -- следите за логической цепочкой, большего не надо.
{{< /hint >}}

## С чем мы работаем?
{{< hint info >}}
**Определение**  
Статистическим экспериментом будем называть тройку \\((\mathfrak{X}, \mathfrak{F}, \mathcal{P}=\\{\mathbb{P}\_\theta: \theta \in \Theta\\})\\), где  
\\(\mathfrak{X}\\) -- множество исходов  
\\(\mathfrak{F}\\) -- множество наблюдаемых событий (\\(\sigma\\)-алгебра на \\(\mathfrak{X}\\))  
\\(\mathcal{P}\\) -- семейство распределений  
\\(\mathbb{P}\_\theta\\) -- конкретное распределение для фиксированного \\(\theta\\)  
\\(\Theta\\) -- множество параметра
{{< /hint >}}


{{< details title="Пояснения" >}}
>Спокойствие! Только спокойствие!

По-порядку:  
\\(\mathfrak{X}\\) -- множество исходов. Здесь всё просто -- множество всего того, что может произойти в нашем эксперименте. Как правило, мы работаем с векторами из \\(\mathbb{R}^n\\).  
\\(\mathfrak{F}\\) -- множество наблюдаемых событий. В основе статистики лежат вероятностные методы, поэтому нам как и прежде нужно уметь задавать вопросы вероятностного характера, поэтому из теорвера мы заимствуем концепцию \\(\sigma\\)-алгебры событий на \\(\mathfrak{X}\\).  
***С оставшимся будет долго и нудно, но один раз это увидеть нужно***  
Давайте для начала попытаемся наскрести остатки теорвера.  
**Определение**  
\\((\Omega, \mathfrak{F}, P)\\) -- вероятностный эксперимент, если
* \\(\mathfrak{F}\\) -- \\(\sigma\\)-алгебра на \\(\Omega\\)
* \\(P: \mathfrak{F}\to [0,1]\\) -- вероятностная мера (распределение) на \\(\mathfrak{F}\\)  

В теории вероятностей мы занимались моделированием одного и только одного эксперимента. Мы не задавались вопросом "а почему такое распределение?". Мы использовали его как данность. С помощью распределения мы получали вероятностные утверждения об исходах эксперимента. Сейчас наоборот. Имея наблюдения, мы будет пытаться сделать какие-то выводы о распределении. 

Ну, не знаю, рост хочу исследовать. Будем брать \\(n\\) человек и измерять рост. Можно взять \\(\mathfrak{X}=\mathbb{R}^+\times\dots\times\mathbb{R}^+\\), \\(\mathfrak{B}(\mathbb{R}^+\times\dots\times\mathbb{R}^+)\\) (борелевская сигма-алгебра). Даже если очень хочется делать это, как-то опираясь на вероятность, то у нас уже затык. Ибо это все, конечно, очень здорово, но я лично понятия не имею, какое распределение имеет рост человека. В теорвере все было легко и просто (конечно, я утрирую), потому что кто-то дал нам задачу и сказал "Случайная величина имеет нормальное распределение". В жизни как-то все сложнее...  

Что делать с распределением? Математики додумались дать ответ: "Ну раз точно мы ничего не знаем, давайте хотя бы зададим допустимое множество, каким наше распределение может быть". Очень часто мы будем предполагать, что наши показания независимы, поэтому далее речь будет идти об одномерных распределениях.
* В определенных ситуациях бывает разумно предполагать, что распределение принадлежит какому-то хорошему семейству распределений, например, нормальному. Такое предположение может быть разумно, когда наши наблюдения являются усреднением каких-то ненаблюдаемых нами явно величин. Например, прибор может выдавать не мгновенные значения силы тока, а усредненные в нескольких временных точках показания. Из-за прелести ЦПТ наше предположение о нормальности будет очень даже обоснованным! 
Вспомним плотность нормального распределения:
\\[p(x;a,\sigma^2)= \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-a)^2}{2\sigma^2}\right).\\] При конкретных значениях \\((a, \sigma^2)\\) мы имеем вполне **конкретное** распределение. Среднее у нас может быть любым, а дисперсия всегда неотрицательна, т.е. если варьировать \\((a, \sigma^2)\\) по множеству \\(\Theta=\mathbb{R}\times[0, \infty]\\), то можно получить все нормальные распределения. Итак, параметр -- \\((a, \sigma^2)\\), параметрическое множество -- \\(\Theta=\mathbb{R}\times[0, \infty]\\), \\(\mathbb{P}\_{\theta\_0=(a\_0,\sigma\_0^2)}\\), где \\(\theta_0 \in \Theta\\) -- конкретное нормальное распределение, имеющее плотность \\(p(x;a_0,\sigma_0^2)\\). А наше \\(\mathcal{P}\\) -- все возможные нормальные распределения, которые можно получить варьированием \\(\theta=(a, \sigma^2)\\) по \\(\Theta\\), т.e. \\(\mathcal{P} = \\{P_\theta: \theta \in \Theta\\}\\). Изучением свойств экспериментов с конечномерными параметрическими множествами занимается ***параметрическая статистика***.
* В худшем случае, когда мы вообще ничего не знаем (или не хотим думать), то прямо и говорим -- "хз, может быть что угодно". Ну, я человек простой, беру и **все** возможные распределения помещаю в \\(\mathcal{P}\\). Распределение (см. определение) -- штука сложная, поэтому статистики вполне естественно характеризуют его чем-то проще, например, функцией распределения (\\(\theta=F\\)), в таком случае \\(\Theta\\) -- множество всех-всех функций распределений, а \\(\mathcal{P}\\) -- множество всех-всех распределений, которые можно получить, если перебрать все-все функции распределения. Удобно ли? Безусловно! Насколько содержательные выводы можно получить, если **совсем** ничего не предполагать? Узнаем в следующих сериях о ***непараметрической статистике***...
{{< /details >}}

>"Статистика не сахар" С.В.

## Задачи мат. статистики
{{< hint info >}}
Реализация эксперимента дает некоторое \\(X\in \mathfrak{X}\\). Задача статистики -- сделать выводы об истинном значении \\(\theta \in \Theta\\).
{{< /hint >}}

{{< details title="Комментарий" >}}
Это очень-мега-супер важно!!! По сути, мы весь курс долбаемся с тем, как бы нам что-то узнать о \\(\theta\\). Истинное значение \\(\theta\\) мы не знаем и никогда не узнаем, но мы очень хотим к нему приблизиться. По мере изучения курса Вы почувствуете, почему нам это важно и как с этим работать.
{{< /details >}}

Какие выводы? Для ответа на этот вопрос перечислим типы задач математической статистики. Каждый тип мы разберем подробнее чуть позже, сейчас просто ознакомимся с тем, что можно делать. 

Итак, в статистике можно заниматься
- [**Точечным оцениванием**](point-estimation/problem):  
  Как прикинуть неизвестное нам теоретическое значение \\(\theta\\)?  
  Ответ задачи: наилучшая прикидка для параметра. 
- [**Доверительным оцениванием**](interval-estimation/):  
  Как прикинуть \\(\theta\\) с уверенностью \\(1-\alpha\\) (напр. с вероятностью 0.95 мой параметр лежит от a до b)?  
  Ответ задачи -- как правило, интервал, границы которого зависят от наблюдений \\([T_1(X), T_2(X)]: P([T_1(X), T_2(X)] \ni \theta) = 1-\alpha\\)
- [**Проверкой гипотез**](hypothesis-testing/):  
	Как задать вопросы к данным? О чем вообще можно спросить? Похожи ли наши данные на распределение-нейм, зависят ли наши данные от параметр-нейм (напр. возраст), похожи ли два набора данных друг на друга -- на такие человеческие вопросы мы научимся отвечать с точки зрения статистики.
- и еще много чем...

Все задачи решаются с использованием понятия **статистики**.

{{< hint info >}}
**Определение**  
Статистикой будем называть измеримую функцию \\(T:\mathfrak{X}\to\mathbb{R}^n\\).
{{< /hint >}}

{{< details title="Пояснения" >}}
***Да, статистика в статистике, и что Вы мне сделаете???***  
Ну, а если серьезно, то... Забудьте на секунду про весь теорвер, то, что Вы только что прочитали про стат. эксперимент. Попытайтесь вспомнить, все те моменты, когда Вы слышали\видели слово "статистика". Статистика игры (дота), статистика матчей (футбол), статистика приемной кампании... Обычно за этим следуют всякие разные числа... В общем-то мат. статистика об этом же (правда, более пафосно)! У Вас есть эксперимент. Результат экперимента -- как правило вектор из \\(\mathbb{R}^n\\). Ну, получили Вы вектор длины, допустим, 1000 (показания с 1000 человек). Не будем же мы глазами на него смотреть -- какой с этого толк. Нас обычно интересует информация попроще и покороче. Ну не знаю, среднее там, разброс, количество экстремальных значений, всякие разные мудреные коэффициенты... Вот это все и есть статистики.

То, что должно остаться в голове:  
**Статистика -- функция от наблюдений.**  
Какая? Да любая, какая хотите (все, что придёт в голову психически здоровому человеку -- измеримо). Даже тупая функция от наблюдений -- тоже статистика. Например, мне 5 лет, и я буду каждому наблюдению сопоставлять число 1, потому что другого я не знаю.
{{< /details >}}

## Модель
Коротко, о раннее уже сказанном:  
\\(\mathfrak{X}\\) определяется видом получаемых данных, как правило, \\(\mathfrak{X}=\mathbb{R}^n\\).  
\\(\mathfrak{F}\\) вообще говоря тоже зависит от вида данных. но как правило не думают и берут \\(\mathfrak{B}\_n\\).  
\\(\mathcal{P}=\\{P_\theta:\theta\in\Theta\\}\\) -- параметризация эксперимента, где \\(P_\theta\\) -- обычно распределение случайного вектора.

В зависимости от вида \\(\Theta\\) различают задачи:
- Параметрические (\\(\dim\Theta = k\\))
- Семипараметрические (\\(\Theta=\Theta_1\times\Theta_2: \dim \Theta_1=k,\dim\Theta_2=\infty\\))
- Непараметрические (все остальные)

P.S. Про семипараметрические модели мы не успеем поговорить, а привести простенький пример не так-то просто, поэтому, пожалуйста, поверьте нам, что между параметрикой и непараметрикой есть что-то еще :).

Далее будем считать, что наши данные имеют вид \\(\Xbi = (X_1,\dots, X_n) \in \mathfrak{X}\\), также будем называть \\(X_i\\) **наблюдениями**. 

## Схемы накопления информации

### Выборка
{{< hint info >}}
**Определение**  
В эксперименте с \\((\mathfrak{X},\mathfrak{F}) = (\mathbb{R}^n, \mathfrak{B}\_n)\\) **выборкой** будем называть \\(X\_1,\dots, X\_n\\), если они суть независимые одинаково распределенные случайные величины (НОРСВ).
{{< /hint >}}

При работе с выборкой мы имеем дело с распределением случайного вектора с независимыми одинаково распределенными компонентами:
\\[\mathbb{P}\_\theta (X\_1 \in A\_1,\dots,X\_n \in A\_n) = P\_\theta (A\_1)\times\dots\times P\_\theta (A\_n),\\]
то есть
\\[\mathbb{P}\_\theta = P_\theta\times\dots\times P_\theta.\\]
Из этого следует, что нет разницы: работать ли с семейством распределений случайного вектора или же с семейством распределений для одной компоненты (компоненты-то все "одинаковые"). Если мы знаем распределение одной компоненты -- мы знаем все! Очевидно, что между распределением вектора и распределением одной случайной величины мы выберем последнее -- оно ж проще! Итак, шо то, шо это...:
\\[\\{\mathbb{P}\_\theta: \theta\in\Theta\\} \leftrightarrow \\{P\_\theta: \theta\in\Theta\\}.\\]
Как ставить эксперимент, чтобы впоследствии суметь сделать выводы о \\(\theta\\)? В случае с одной выборкой рассматривают:
1. Повторное проведение эксперимента \\(n\\) раз в одних и тех же условиях.
2. Выбор из генеральной совокупности (статистически однородное множество объектов):  
   \\(N\\) -- количество элементов генеральной совокупности,  
   \\(n\\) -- количество исследуемых нами объектов (случайно из \\(N\\)).  
   Строго говоря, вспоминая задачи с картами, мы можем сказать, что выбор из совокупности без возвращения влечет зависимость событий, но при \\(n\\: <<\\: N\\) наш набор можно считать выборкой.

### Несколько выборок
Пусть \\(m\\) -- количество выборок (фиксированное число)  
Наблюдения: \\((X_1, z_1), \dots, (X_n, z_n)\\), где  
\\(X\_i\\) -- интересующая нас характеристика,  
\\(z\_i\in \\{1,\dots, m\\}\\) -- номер выборки.  
Исследуем \\(P\_{\theta, z} \\) -- распределение наблюдений при фиксированном значении \\(z\\).

### Регрессия
Отметим, что зачастую мы имеем не только сведения об интересующем нас показателе, например росте, но так же некоторый набор сопутствующих характеристик/факторов. Например, вес, пол, этничность и проч. Такие признаки признаки называются ковариатами. Они не являются ключевой целью исследования, однако вполне естественно предполагать, что какие-то из них могут оказывать влияние на результат эксперимента. Как учесть это самое влияние? Ответов вагон и маленькая тележка, мы же остановимся на регрессионных методах. 

Итак, статистические данные имеют вид:  
\\((Y\_1, {\bf z}\_1), \dots,(Y\_n, {\bf z}\_n),\\) где  
\\(Y\_i\\) -- наблюдение (интересующая нас характеристика),  
\\({\bf z}\_i\\) -- вектор ковариат.  
Изучаем \\(P\_{\theta, {\bf z}} \\) -- распределение наблюдений при фиксированном значении \\({\bf z}\in\mathbb{R}^d\\).

{{< hint info >}}
**Определение**  
Регрессией случайной величины \\(Y\\) по \\(X\\) будем называть \\(\E(Y|X)\\).
{{< /hint >}}

В рассматриваемой нами модели имеем: \\(\E\_\theta(Y|{\bf z})\\) -- мат. ожидание \\(Y\\) при фиксированном \\({\bf z}\\).

{{< hint info >}}
**Определение**  
Регрессионная модель:  
\\[\E\_\theta(Y|{\bf z}) = g({\bf z};\theta),\\]
где \\(g({\bf z};\theta)\\) -- известная, неслучайная функция.
{{< /hint >}}

{{< details title="Пояснения">}}
Моделируем среднее значение какого-то показателя при фиксированных ковариатах. Среднее значение роста человека, если кто-то мне скажет его возраст, вес, этничность и пол. В правой части какая-то ж, ну в смысле \\(g\\). Как среднее зависит от ковариат? ДА ХРЕН ЕГО ЗНАЕТ, ЭТО ЖЕ ПРИРОДНОЕ ЯВЛЕНИЕ. В общем случае в правой части можно писать хоть синус^2(возраста) + 112*вес^3. Да только это как-то мудрено. Не надо усложнять жизнь. По этой и только этой причине повсеместно распространены модели линейной регрессии. 
{{< /details >}}

{{< hint info >}}
**Определение**  
Модель линейной регрессии:  
\\[\E\_\theta(Y|{\bf z}) = \Xb^T\\!({\bf z}){\bf \beta},\\]
\\(\Xb^T\\!({\bf z})\\) -- матрица регрессоров,  
\\(\theta=(\beta, \sigma)\\) -- параметр модели
{{< /hint >}}

{{< details title="Пояснения">}}
На всякий случай: мы не можем моделировать (предсказывать) случайную величину. Она же ну... Случайная... Поэтому моделируем че попроще -- среднее весьма разумный выбор. 

Очевидно, что правая часть вселяет ужас. 
По порядку, пусть есть интересующая нас характеристика \\(Y\\), и две ковариаты \\(z_1, z_2\\) (возраст и вес, напр.). Моделирую \\(\E(Y|z_1,z_2)\\) линейной функцией, например, \\(\beta_0 + \beta_1z_1+\beta_2z_2\\). Ну типа \\(kx+b\\)... Где беты можно интерпретировать как **степень влияния** каждой из ковариат. А так это параметры, КОТОРЫЕ МЫ НЕ ЗНАЕМ И НИКОГДА НЕ УЗНАЕМ, но очень хотим узнать. Как мы их оценим? Потом-потом-потом. Щас главное модель. А можно ли моделировать как \\(\beta_0 + \beta_1\sin(z_1)+\beta_2z_2^3\\)? Можно. Модель линейна в параметрах.

Дальше вспоминаем умножение матриц... Пусть есть \\(n\\) человек, мы с них собрали данные и знаем как игреки \\(\Ybi=(Y_1,\dots,Y_n)^T\\), так и зет \\((z_{11},z_{12}),\dots, (z_{n1},z_{n2})\\). Для каждого наблюдения можно написать нашу модель:
\\[\E(Y_1|z_1,z_2) = \beta_0 + \beta_1z_{11}+\beta_2z_{12}\\]
\\[\dots\\]
\\[\E(Y_n|z_1,z_2) = \beta_0 + \beta_1z_{n1}+\beta_2z_{n2}\\]
\\[\E(\Ybi\\;|{\bf z}) = 
\begin{pmatrix}
1 & z\_{11} & z\_{12} \\\
\dots & \dots & \dots \\\
1 & z\_{n1} & z\_{n2} \\\
\end{pmatrix}
\begin{pmatrix}
\beta\_0\\\
\beta\_1\\\
\beta\_2
\end{pmatrix}=\Xb^T\\!({\bf z}){\bf \beta}
\\]
Как уже упоминалось, можно добавить к ковариатам степени и прочую лабуду, поэтому матрица \\({\bf X}\\) будет как-то зависеть от ковариат. Нахрена транспонирование? Вопрос риторический. Можно найти этому оправдания, но я не перестану верить, что кто-то просто любит выделываться.

В определении модели сказано, что еще есть некоторая сигма... Короткий ответ следующий: одно лишь среднее (что мы моделируем) не характеризует распределение, его недостаточно. Мы будем работать с нормальным распределением, для которого среднего и дисперсии будет достаточно. Не грузитесь сейчас.
{{< /details >}}

## Асимптотический подход
Строго говоря, в подавляющем большинстве случаев статистика, при применении ее к нашим прикладным задачам с конечным размером выборки \\(n\\), **не умеет** давать нам ответы на задаваемые вопросы. Потому что потому. Потом увидите, что разработано, и поймете, собственно, почему так. В любом случае, по этой причине активно применяются так называемые **асимптотические методы**.

Рассмотрим последовательность стат. экспериментов \\((\mathfrak{X}\_n, \mathfrak{F}\_n, \mathcal{P}\_n), \mathcal{P}\_n=\\{\mathbb{P}\_{n,\theta}: \theta \in \Theta\\}\\) при \\(n\to\infty\\). 

{{< details title="Пояснения" >}}
**Как смотреть на эту прелесть?**  
Во-первых, ЛЮБАЯ асимптотика в этой жизни -- всего лишь теория. 
Во-вторых, вот прямо сейчас, читая это в первый раз, всего прикола вы не почувствуете. По мере углубления в курс при должном прилежании все дойдет. 

Так вот, давайте построим последовательность гипотетических экспериментов по измерению роста у
- 1-го человека, \\((\mathfrak{X}\_1=\mathbb{R}^+)\\)
- 2-х человек, \\((\mathfrak{X}\_2=\mathbb{R}^+\times\mathbb{R}^+)\\)
- ...
- \\(n\\) человек, \\((\mathfrak{X}\_n=\mathbb{R}^+\times\dots\times\mathbb{R}^+)\\)
- ... Да, и так для любого натурального \\(n\\). Смекаешь?

Возможно ли это в реальности? Нет. Волнует ли это математиков? Тоже нет.
Так, для каждого \\(n\\) имеется своя \\(\sigma\\)-алгебра \\(\mathfrak{F}\_n\\) и, соответственно, свое семейство распределений \\(\mathcal{P}\_n\\), адаптированное под растущую размерность выборки. Асимптотический подход используется как мысленная реализация идеи, что с увеличением данных мы будем иметь больше информации о явлении и лучше сможем оценивать то, что нам хочется.
{{< /details >}}

### В задачах точечного оценивания
При каждом \\(n\\) рассматриваем также статистику \\(\hat\theta\_n:\mathfrak{X}\_n\to\Theta\\) для решения той или иной задачи. Пусть \\(\rho(\theta\_1,\theta\_2)\\) -- расстояние на \\(\Theta\\).

{{< hint info >}}
**Определение**  
Оценка \\(\hat\theta\_n\\) -- ***состоятельная оценка*** параметра \\(\theta\\), если
\\[\forall \varepsilon > 0 \quad \P_\theta(\rho(\hat\theta_n, \theta) > \varepsilon) \to 0, \text{ при } n\to\infty\\]
или
\\[\hat\theta_n\to\theta, \quad \forall \theta\in\Theta.\\]
{{< /hint >}}

{{< details title="Пояснения" >}}
Оценка -- прикидка для чего-то неизвестного. Нам никто не регламентировал, **как** строить оценку. Я могу быть дурачком и при растущем объеме выборки для каждой реализации использовать функцию \\(\hat\theta\_n(\Xbi) \equiv 1\\). Это оценка? Да. Есть ли от нее толк? Очень сомневаюсь, ибо информацию о выборке мы как-то не задействуем. То есть, у нас есть какое-то скрытое природой значение параметра \\(\theta\\), мы собираем 10, 100, 10000 наблюдений и всегда говорим, что \\(\theta=1\\). И так делать валидно. Но не хорошо. **Состоятельность** -- один из способов сказать "что такое хорошо и что такое плохо" в статистике. Чисто с человеческой точки зрения: если мы собираем все больше данных, то хорошая оценка должна приближаться к неизвестному теоретическому значению, ведь информации о явлении все больше. Для любого \\(\theta\\) пишется потому, что истинного значения \\(\theta\\) мы не знаем, и мы хотим, чтобы для любого \\(\theta\\), КАКИМ БЫ ОНО НИ БЫЛО, оценка (функция, **зависящая от наблюдений**) сходилась по вероятности к этому самому \\(\theta\\).

**Важно**  
Определение ничего не говорит о том, **как** доказать состоятельность и, к счастью, мы тоже особо не будем этим заниматься, поскольку существуют теоремы для широкого класса оценок, которые мы один раз выведем и после чего скажем, что все хорошо и мы молодцы. Результат теоретический, но на практике несостоятельными оценками не пользуются.
{{< /details >}}

### В задачах доверительного оценивания
В задачах доверительного оценивания можно говорить об асимптотических доверительных областях и критериях соответственно.

\\(\P\_\theta(\hat\Theta_n\ni\theta)\to 1-\alpha,\\: \forall \theta\in\Theta\\) -- асимптотическая доверительная область,  
\\(\P\_\theta(\hat\Theta_n\ni\theta)\geq 1-\alpha,\\: \forall \theta\in\Theta\\) -- точная доверительная область.
